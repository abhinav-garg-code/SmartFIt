import express from "express";
import multer from "multer";
import cors from "cors";
import dotenv from "dotenv";
import { VertexAI } from "@google-cloud/vertexai";

dotenv.config();

const app = express();
app.use(cors());
app.use(express.json());
app.use(express.urlencoded({ extended: true }));

const upload = multer({ storage: multer.memoryStorage() });

// Replace with your actual GCP project ID from the new project
const project = "smartfit-478109";
const location = "us-central1";
const model = "gemini-2.5-pro";

let vertex_ai;
let generativeModel;

try {
  vertex_ai = new VertexAI({ project: project, location: location });
  generativeModel = vertex_ai.getGenerativeModel({
    model: model,
  });
  console.log("Vertex AI initialized successfully");
} catch (err) {
  console.error("Failed to initialize Vertex AI:", err.message);
}

// Health check endpoint
app.get("/health", (req, res) => {
  res.json({ status: "ok", vertexAiInitialized: !!generativeModel });
});

// Accept up to 4 image fields: image, image1, image2, image3
app.post("/api/analyze", upload.fields([
  { name: 'image', maxCount: 1 },
  { name: 'image1', maxCount: 1 },
  { name: 'image2', maxCount: 1 },
  { name: 'image3', maxCount: 1 },
]), async (req, res) => {
  try {
    console.log("=== Received request to /api/analyze ===");
    console.log("Body keys:", Object.keys(req.body));
    console.log("Prompt:", req.body.prompt);
    console.log("Files:", req.files ? Object.keys(req.files) : 'none');

    const { prompt } = req.body;
    // gather any uploaded files from req.files (upload.fields stores them as arrays)
    const imageFiles = [];
    if (req.files && typeof req.files === 'object') {
      Object.values(req.files).forEach((arr) => {
        if (Array.isArray(arr)) arr.forEach((f) => imageFiles.push(f));
      });
    }

    if (!prompt && imageFiles.length === 0) {
      console.log("ERROR: No prompt or image provided");
      return res.status(400).json({ error: "No prompt or image provided.", success: false });
    }

    if (!generativeModel) {
      console.log("ERROR: Vertex AI not initialized");
      return res.status(500).json({ error: "Vertex AI not initialized", success: false });
    }

    console.log("Building request with prompt:", prompt.substring(0, 50));

    const parts = [
      { text: prompt || "Analyze this image." },
    ];

    if (imageFiles.length) {
      imageFiles.forEach((imageFile, idx) => {
        try {
          console.log("Adding image to request, size:", imageFile.size, 'fieldIndex', idx);
          parts.push({
            inlineData: {
              mimeType: imageFile.mimetype,
              data: imageFile.buffer.toString("base64"),
            },
          });
        } catch (e) {
          console.warn('Failed to add an uploaded image to parts', e);
        }
      });
    }

    console.log("Sending request to Vertex AI with", parts.length, "parts");

    const result = await generativeModel.generateContent({
      contents: [{ role: "user", parts: parts }],
      generationConfig: {
        maxOutputTokens: 2048,
        temperature: 0.4,
      },
    });

    console.log("Received response from Vertex AI");

    const responseData = result.response;
    
    if (!responseData) {
      console.log("ERROR: No responseData from Vertex AI");
      return res.status(500).json({ 
        error: "No response from Vertex AI",
        success: false
      });
    }

    if (!responseData.candidates || responseData.candidates.length === 0) {
      console.log("ERROR: No candidates in response");
      return res.status(500).json({ 
        error: "No content generated by the model",
        success: false
      });
    }

    const candidate = responseData.candidates[0];
    const textContent = candidate.content?.parts?.[0]?.text || "";
    
    if (!textContent) {
      console.log("WARNING: No text content extracted");
    }

    console.log("Extracted text length:", textContent.length);
    console.log("Sending success response");

    const responsePayload = {
      success: true,
      data: {
        candidates: [
          {
            content: {
              parts: [{ text: textContent }]
            }
          }
        ]
      },
    };

    res.setHeader('Content-Type', 'application/json');
    return res.json(responsePayload);

  } catch (err) {
    console.error("EXCEPTION in /api/analyze:", err.message);
    console.error("Stack:", err.stack);
    res.setHeader('Content-Type', 'application/json');
    return res.status(500).json({ 
      error: String(err.message || err),
      success: false
    });
  }
});

const port = process.env.PORT || 5174;
app.listen(port, () => {
  console.log("Backend server listening on http://localhost:" + port);
  console.log("Using Vertex AI Project: " + project + " in " + location);
});

// Global error handler to ensure JSON responses for multer/other errors
app.use((err, req, res, next) => {
  if (!err) return next();
  console.error('Global error handler caught:', err && err.message ? err.message : err);
  // Multer errors should be returned as JSON instead of default HTML error page
  if (err.name === 'MulterError' || err instanceof multer.MulterError) {
    return res.status(400).json({ error: err.message || 'Multer error', success: false });
  }
  // For other errors, return JSON as well
  return res.status(500).json({ error: String(err.message || err), success: false });
});
